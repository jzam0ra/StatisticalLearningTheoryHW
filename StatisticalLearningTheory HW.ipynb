{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d716dab1",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb53f7",
   "metadata": {},
   "source": [
    "# 1) \n",
    "Suppose that we use a perceptron to detect spam messages. Let's say that each e-mail message is represented by the frequency of occurrence of keywords, and the output is $+1$ if the message is considered spam.<br>\n",
    "    a) Can you think of some keywords that will end up with a large positive weight in the perceptron?<br>\n",
    "    b) How about keywords that will get a negative weight?<br>\n",
    "    c) What parameter in the perceptron directly affects how many borderline messages end up being classified as spam?<br>\n",
    "\n",
    "# 2)\n",
    "The weight update rule \n",
    "    \\begin{align}\n",
    "    \\mathbf{w}(t + 1) = \\mathbf{w}(t) + y(t)\\mathbf{x}(t)\n",
    "    \\end{align}\n",
    "    has the nice interpretation that it moves in the direction of classifying $\\mathbf{x}(t)$ correctly.<br>\n",
    "    a)Show that $y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t) < 0$. [Hint: $\\mathbf{x}(t)$ is misclassified by $\\mathbf{w}(t)$.]<br>\n",
    "    b)Show that $y(t)\\mathbf{w}^{T}(t+1)\\mathbf{x}(t) > y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t)$. [Hint: Use (1).]<br>\n",
    "    c)As far as classifying $\\mathbf{x}(t)$ is concerned, argue that the move from $\\mathbf{w}(t)$ to $\\mathbf{w}(t + 1)$ is a move in the right direction.<br>\n",
    "    \n",
    "# 3)\n",
    "Here is an experiment that illustrates the difference between a single bin and multiple bins. Run a computer simulation for flipping 1000 fair coins. Flip each coin independently times. Let's focus on 3 coins as follows: $c_1$ is the first coin flipped; $c_{rand}$ is a coin you choose at random; $c_{min}$ is the coin that had the minimum frequency of heads (pick the earlier one in case of a tie). Let $\\nu_1$ , $\\nu_{rand}$ and $\\nu_{min}$ be the fraction of heads you obtain for the respective three coins.<br>\n",
    "    a) What is $\\mu$ for the three coins selected?<br>\n",
    "    b) Repeat this entire experiment a large number of times (e.g., 100000 runs of the entire experiment) to get several instances of $\\nu_1$ , $\\nu_{rand}$ and $\\nu_{min}$ and plot the histograms of the distributions of $\\nu_1$, $\\nu_{rand}$ and $\\nu_{min}$Â· Notice that which coins end up being $c_{rand}$ and $c_{min}$ may differ from one run to another.<br>\n",
    "    c) Using (b), plot estimates for $\\mathbb{P}[|\\nu-\\mu| > \\epsilon]$ as a function of $\\epsilon$, together with the Hoeffding bound $2e^{-2\\epsilon^2N}$ (on the same graph).<br>\n",
    "    d) Which coins obey the Hoeffding bound, and which ones do not? Explain why.<br>\n",
    "    e) Relate part (d) to the multiple bins in Figure 1.10.<br>\n",
    "    \n",
    "# 4) \n",
    "We are given a data set $\\mathcal{D}$ of 25 training examples from an unknown target function $f:\\mathcal{X}\\to\\mathcal{Y}$, where $\\mathcal{X}=\\mathbb{R}$ and $\\mathcal{Y}=\\{-1,+1\\}$. To learn $f$, we use a simple hypothesis set $\\mathcal{H} = \\{h_1, h_2\\}$ where $h_1$ is the constant $+1$ function and $h_2$ is the constant $-1$.\\\\ \n",
    "    We consider two learning algorithms, $S$ (smart) and $C$ (crazy). $S$ chooses the hypothesis that agrees the most with $\\mathcal{D}$ and $C$ chooses the other hypothesis deliberately. Let us see how these algorithms perform out of sample from the deterministic and probabilistic points of view. Assume in the probabilistic view that there is a probability distribution on $\\mathcal{X}$, and let $\\mathbb{P}[f(x) = +1] = p$.<br>\n",
    "    a) Can $S$ produce a hypothesis that is guaranteed to perform better than random on any point outside $\\mathcal{D}$?<br>\n",
    "    b) Assume for the rest of the exercise that all the examples in $\\mathcal{D}$ have $y_n = +1$. Is it \\textit{possible} that the hypothesis that $C$ produces turns out to be better than the hypothesis that $S$ produces?<br>\n",
    "    c) If $p = 0.9$, what is the probability that $S$ will produce a better hypothesis than $C$?<br>\n",
    "    d) Is there any value of $p$ for which it is more likely than not that $C$ will produce a better hypothesis than $S$?<br>\n",
    "    \n",
    "# 5)\n",
    "A friend comes to you with a learning problem. She says the target function $f$ is completely unknown, but she has 4000 data points. She is willing to pay you to solve her problem and produce for her a $g$ which approximates $f$. What is the best that you can promise her among the following:<br>\n",
    "    a) After learning you will provide her with a $g$ that you will guarantee approximates well out of sample.<br>\n",
    "    b) After learning you will provide her with a $g$, and with high probability the $g$ which you produce will approximate well out of sample.<br>\n",
    "    c) One of two things will happen:<br>\n",
    "        i) you will produce a hypothesis $g$;<br>\n",
    "        ii) you will declare that you failed.<br>\n",
    "    If you do return a hypothesis $g$, then with high probability the $g$ which you produce will approximate $f$ well out of sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73261147",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8ac03",
   "metadata": {},
   "source": [
    "# 1\n",
    "a) e-mails with words like \\textit{offer!, free, won, Nigeria, prince}, among many others, are commonly used words in spam messages that intend to scam people, hence they are likely to end up with a large positive weight.<br>\n",
    "\n",
    "b) On the other hand, words like \\textit{cordially, sincerely, hello}, are likely to get negative weight since they are common on e-mails.<br>\n",
    "\n",
    "c) The parameter $b$, also known as the bias term or the threshold of the model, is the one that directly affects which messages end up being classified as spam and which don't. It is natural for the way it is defined, or it could also be thought in the $2$-dimensional case: parameter $b$ determines the $y$ intercept of the line that separates the dataseet, so points close to the line, are directly affected by the changes to $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4caded",
   "metadata": {},
   "source": [
    "# 2\n",
    "\n",
    "a) Since the perceptron algorythm chooses on an iteration $t$ an example $\\mathbf{x}(t)$ which is misclassified by $\\mathbf{w}(t)$, we have that $y(t) \\neq sign(\\mathbf{w}^{T}(t)\\mathbf{x}(t))$, that is, they have different sign, hence the product $y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t)$ satisfies\n",
    "        $$\n",
    "        y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t) < 0.\n",
    "        $$\n",
    "        \n",
    "b) From (1) we have that \n",
    "        \\begin{align*}\n",
    "            y(t)\\mathbf{w}^{T}(t+1)\\mathbf{x}(t) &= y(t)[\\mathbf{w}^{T}(t) + y(t)\\mathbf{x}^{T}(t)]\\mathbf{x}(t)\\\\\n",
    "            &= y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t)+(y(t))^2\\|\\mathbf{x}\\|^2\\\\\n",
    "            &> y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t).\n",
    "        \\end{align*}\n",
    "        \n",
    "c) From $b$) we can see that after each iteration $t$, the value $y(t)\\mathbf{w}^{T}(t)\\mathbf{x}(t)$ is increasing, hence, as the only value that is changing from one iteration to the next one is $\\mathbf{w}^{T}(t)$, while the others remain invariant, what we are doing is changing $\\mathbf{w}^{T}(t)$ so that $\\mathbf{x}(t)$ \"gets closer\" to being properly classified.<br>\n",
    "\n",
    "In other words, if $y(t)$ is positive, then $\\mathbf{w}^{T}(t)\\mathbf{x}(t)$ is negative, and we've moved it towards the positive side by increasing it. Similarly, if $y(t)$ is negative, then $\\mathbf{w}^{T}(t)\\mathbf{x}(t)$ is positive, and we've moved it towards the negative side by decreasing it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff781160",
   "metadata": {},
   "source": [
    "# 3\n",
    "The code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8dc04849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flip_coins (generic function with 1 method)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "function flip_coins(total_coins)\n",
    "    \n",
    "    hts = zeros(total_coins) #head: 1, tail: 0\n",
    "    probs = rand(Uniform(),total_coins)\n",
    "    for i = 1:total_coins\n",
    "        if probs[i]>0.5\n",
    "            hts[i]=1\n",
    "        end\n",
    "    end\n",
    "    return hts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88a79146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hoeffding_bound (generic function with 1 method)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function hoeffding_bound(epsilon, n)\n",
    "    return 2.0*exp(-2.0*n*epsilon^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0d8b343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_once (generic function with 2 methods)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_once(total_coins, total_flips)\n",
    "            v1, vrand, vmin = nothing, nothing, nothing;\n",
    "            crand = rand(1:total_coins)\n",
    "            hts_sum = zeros(total_coins,1) # store the sum of heads in total_flips\n",
    "    \n",
    "            for flip in 1:total_flips\n",
    "                hts_sum = hts_sum + flip_coins(total_coins)\n",
    "            end\n",
    "            hts_freq = hts_sum/total_flips\n",
    "    \n",
    "            v1 = hts_freq[1]\n",
    "            vrand = hts_freq[crand]\n",
    "            cmin = argmin(hts_sum)\n",
    "            vmin = hts_freq[cmin]\n",
    "    \n",
    "            \n",
    "            print(\"Frequency of first coin:\",v1)\n",
    "            print(\"Frequency of a random coin:\", vrand)\n",
    "            print(\"Frequency of the coin with minimum frequency:\", vmin)\n",
    "            \n",
    "            return v1,vrand,vmin\n",
    "            \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "659c1c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of first coin:0.3Frequency of a random coin:0.4Frequency of the coin with minimum frequency:0.1"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3, 0.4, 0.1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_once(1000,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82587351",
   "metadata": {},
   "source": [
    "# 4\n",
    "a) No, it can't. If the target function $f$ consisted of the function that is $-1$ everywhere except on the 25 points of $\\mathcal{D}$, then $S$ would choose $h_1$, and it wouldn't coincide with $f$ anywhere outside $\\mathcal{D}$. On the other hand, a function that chooses randomly between $-1$ and $+1$, will match $f$ outside $\\mathcal{D}$ with a probability of $1/2$, thus performing better that the hyphotesis chosen by $S$.<br>\n",
    "\n",
    "b) Yes, it is. For instance, for the example in $a$) $C$ matches $f$ everywhere outside $\\mathcal{D}$, that is, with probability $1$, better than $S$ which has probability $0$ of matching $f$ outside $\\mathcal{D}$.<br>\n",
    "\n",
    "c) $1$.<br>\n",
    "\n",
    "d) $p<0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5723ca",
   "metadata": {},
   "source": [
    "# 5\n",
    "The best one could promise is $c$: from the theory we've seen, we know that it isn't possible to guarantee that we will learn a function given a dataset, no matter how big it is, hence we can't promise $a$). On the other hand, we know that regardless of the Hoeffding inequality providing theoretical support for \\textit{probably} learning a function, it could be the case that we cannot learn a function that probably approximates $f$ well out of sample. That leaves $c$) as our best option; if we don't fail to learn, we could return a hypothesis $g$ that probably (thanks to Hoeffding's inequality) approximates $f$ well out of sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
